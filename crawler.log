22.11.16 01:49:58 INFO            net.crawler #             Application.name = web crawler
22.11.16 01:49:58 INFO            net.crawler #                      version = 0.1
22.11.16 01:49:58 INFO            net.crawler #                 inifile_name = undefined
22.11.16 01:49:58 INFO            net.crawler #                          log = <logging.Logger object at 0x7f604cdc9fd0>
22.11.16 01:49:58 INFO            net.crawler #        remote_logger_enabled = False
22.11.16 01:49:58 INFO            net.crawler #                 loghost_port = 9020
22.11.16 01:49:58 INFO            net.crawler #                 loghost_name = localhost
22.11.16 01:49:58 INFO            net.crawler #                      logfile = crawler.log
22.11.16 01:49:58 INFO            net.crawler #                 starting_url = http://localhost/~map/testweb/
22.11.16 01:49:58 INFO            net.crawler # web crawler 0.1 is starting
22.11.16 01:49:58 DEBUG           net.crawler # Next parse result = ParseResult(scheme='http', netloc='localhost', path='/~map/testweb/', params='', query='', fragment='')
22.11.16 01:49:58 DEBUG           net.crawler # Processing http://localhost/~map/testweb/ with hash value a82fca2019df9b43d0fa97f4cba277a5
22.11.16 01:49:58 INFO            net.crawler # Visiting http://localhost/~map/testweb/
22.11.16 01:49:58 DEBUG           net.crawler # Next parse result = ParseResult(scheme='http', netloc='localhost', path='/~map/testweb/index2.html', params='', query='', fragment='')
22.11.16 01:49:58 DEBUG           net.crawler # Processing http://localhost/~map/testweb/index2.html with hash value 2a7a5d436306036d85f26b30160cff48
22.11.16 01:49:58 INFO            net.crawler # Visiting http://localhost/~map/testweb/index2.html
22.11.16 01:49:58 DEBUG           net.crawler # Next parse result = ParseResult(scheme='http', netloc='localhost', path='/~map/testweb/index3.html', params='', query='', fragment='')
22.11.16 01:49:58 DEBUG           net.crawler # Processing http://localhost/~map/testweb/index3.html with hash value 4034293276428b374ccd042e062424e3
22.11.16 01:49:58 INFO            net.crawler # Visiting http://localhost/~map/testweb/index3.html
22.11.16 01:49:58 DEBUG           net.crawler # Next parse result = ParseResult(scheme='http', netloc='localhost', path='/~map/testweb/index6.html', params='', query='', fragment='')
22.11.16 01:49:58 DEBUG           net.crawler # Processing http://localhost/~map/testweb/index6.html with hash value 1614847c29f2ae14d8c886e97ee64667
22.11.16 01:49:58 INFO            net.crawler # Visiting http://localhost/~map/testweb/index6.html
22.11.16 01:49:58 DEBUG           net.crawler # Next parse result = ParseResult(scheme='http', netloc='localhost', path='/~map/testweb/index.html', params='', query='', fragment='')
22.11.16 01:49:58 DEBUG           net.crawler # Processing http://localhost/~map/testweb/index.html with hash value 44801ccea5dcbe4d3486f3c302c357a7
22.11.16 01:49:58 INFO            net.crawler # Visiting http://localhost/~map/testweb/index.html
22.11.16 01:49:58 DEBUG           net.crawler # Next parse result = ParseResult(scheme='http', netloc='localhost', path='/~map/testweb/index2.html', params='', query='', fragment='')
22.11.16 01:49:58 DEBUG           net.crawler # Processing http://localhost/~map/testweb/index2.html with hash value 2a7a5d436306036d85f26b30160cff48
22.11.16 01:49:58 INFO            net.crawler # Url was already visited
22.11.16 01:49:58 DEBUG           net.crawler # Next parse result = ParseResult(scheme='http', netloc='localhost', path='/~map/testweb/index5.html', params='', query='', fragment='')
22.11.16 01:49:58 DEBUG           net.crawler # Processing http://localhost/~map/testweb/index5.html with hash value 7f41433a058018edd43b03fe18c9c325
22.11.16 01:49:58 INFO            net.crawler # Visiting http://localhost/~map/testweb/index5.html
22.11.16 01:49:58 DEBUG           net.crawler # Next parse result = ParseResult(scheme='http', netloc='localhost', path='/~map/testweb/index.html', params='', query='', fragment='')
22.11.16 01:49:58 DEBUG           net.crawler # Processing http://localhost/~map/testweb/index.html with hash value 44801ccea5dcbe4d3486f3c302c357a7
22.11.16 01:49:58 INFO            net.crawler # Url was already visited
22.11.16 01:49:58 DEBUG           net.crawler # Next parse result = ParseResult(scheme='http', netloc='localhost', path='/~map/testweb/index4.html', params='', query='', fragment='')
22.11.16 01:49:58 DEBUG           net.crawler # Processing http://localhost/~map/testweb/index4.html with hash value d95f56b91c09e0cf0daf83f8dfa0a041
22.11.16 01:49:58 INFO            net.crawler # Visiting http://localhost/~map/testweb/index4.html
22.11.16 01:49:58 DEBUG           net.crawler # Next parse result = ParseResult(scheme='http', netloc='localhost', path='/~map/testweb/index.html', params='', query='', fragment='')
22.11.16 01:49:58 DEBUG           net.crawler # Processing http://localhost/~map/testweb/index.html with hash value 44801ccea5dcbe4d3486f3c302c357a7
22.11.16 01:49:58 INFO            net.crawler # Url was already visited
22.11.16 01:49:58 INFO            net.crawler # No more urls to process.
22.11.16 01:49:58 INFO            net.crawler # web crawler 0.1 is done
22.11.16 01:53:19 INFO            net.crawler #             Application.name = web crawler
22.11.16 01:53:19 INFO            net.crawler #                      version = 0.1
22.11.16 01:53:19 INFO            net.crawler #                 inifile_name = undefined
22.11.16 01:53:19 INFO            net.crawler #                          log = <logging.Logger object at 0x7fa043245fd0>
22.11.16 01:53:19 INFO            net.crawler #        remote_logger_enabled = False
22.11.16 01:53:19 INFO            net.crawler #                 loghost_port = 9020
22.11.16 01:53:19 INFO            net.crawler #                 loghost_name = localhost
22.11.16 01:53:19 INFO            net.crawler #                      logfile = crawler.log
22.11.16 01:53:19 INFO            net.crawler #                 starting_url = http://localhost/~map/testweb/
22.11.16 01:53:19 INFO            net.crawler # web crawler 0.1 is starting
22.11.16 01:53:19 DEBUG           net.crawler # Next parse result = ParseResult(scheme='http', netloc='localhost', path='/~map/testweb/', params='', query='', fragment='')
22.11.16 01:53:19 DEBUG           net.crawler # Processing http://localhost/~map/testweb/ with hash value a82fca2019df9b43d0fa97f4cba277a5
22.11.16 01:53:19 INFO            net.crawler # Visiting http://localhost/~map/testweb/
22.11.16 01:53:19 DEBUG           net.crawler # Next parse result = ParseResult(scheme='http', netloc='localhost', path='/~map/testweb/index2.html', params='', query='', fragment='')
22.11.16 01:53:19 DEBUG           net.crawler # Processing http://localhost/~map/testweb/index2.html with hash value 2a7a5d436306036d85f26b30160cff48
22.11.16 01:53:19 INFO            net.crawler # Visiting http://localhost/~map/testweb/index2.html
22.11.16 01:53:19 DEBUG           net.crawler # Next parse result = ParseResult(scheme='http', netloc='localhost', path='/~map/testweb/index3.html', params='', query='', fragment='')
22.11.16 01:53:19 DEBUG           net.crawler # Processing http://localhost/~map/testweb/index3.html with hash value 4034293276428b374ccd042e062424e3
22.11.16 01:53:19 INFO            net.crawler # Visiting http://localhost/~map/testweb/index3.html
22.11.16 01:53:19 DEBUG           net.crawler # Next parse result = ParseResult(scheme='http', netloc='localhost', path='/~map/testweb/index6.html', params='', query='', fragment='')
22.11.16 01:53:19 DEBUG           net.crawler # Processing http://localhost/~map/testweb/index6.html with hash value 1614847c29f2ae14d8c886e97ee64667
22.11.16 01:53:19 INFO            net.crawler # Visiting http://localhost/~map/testweb/index6.html
22.11.16 01:53:19 DEBUG           net.crawler # Next parse result = ParseResult(scheme='http', netloc='localhost', path='/~map/testweb/index.html', params='', query='', fragment='')
22.11.16 01:53:19 DEBUG           net.crawler # Processing http://localhost/~map/testweb/index.html with hash value 44801ccea5dcbe4d3486f3c302c357a7
22.11.16 01:53:19 INFO            net.crawler # Visiting http://localhost/~map/testweb/index.html
22.11.16 01:53:19 DEBUG           net.crawler # Next parse result = ParseResult(scheme='http', netloc='localhost', path='/~map/testweb/index2.html', params='', query='', fragment='')
22.11.16 01:53:19 DEBUG           net.crawler # Processing http://localhost/~map/testweb/index2.html with hash value 2a7a5d436306036d85f26b30160cff48
22.11.16 01:53:19 INFO            net.crawler # Url was already visited
22.11.16 01:53:19 DEBUG           net.crawler # Next parse result = ParseResult(scheme='http', netloc='localhost', path='/~map/testweb/index5.html', params='', query='', fragment='')
22.11.16 01:53:19 DEBUG           net.crawler # Processing http://localhost/~map/testweb/index5.html with hash value 7f41433a058018edd43b03fe18c9c325
22.11.16 01:53:19 INFO            net.crawler # Visiting http://localhost/~map/testweb/index5.html
22.11.16 01:53:19 DEBUG           net.crawler # Next parse result = ParseResult(scheme='http', netloc='localhost', path='/~map/testweb/index.html', params='', query='', fragment='')
22.11.16 01:53:19 DEBUG           net.crawler # Processing http://localhost/~map/testweb/index.html with hash value 44801ccea5dcbe4d3486f3c302c357a7
22.11.16 01:53:19 INFO            net.crawler # Url was already visited
22.11.16 01:53:19 DEBUG           net.crawler # Next parse result = ParseResult(scheme='http', netloc='localhost', path='/~map/testweb/index4.html', params='', query='', fragment='')
22.11.16 01:53:19 DEBUG           net.crawler # Processing http://localhost/~map/testweb/index4.html with hash value d95f56b91c09e0cf0daf83f8dfa0a041
22.11.16 01:53:19 INFO            net.crawler # Visiting http://localhost/~map/testweb/index4.html
22.11.16 01:53:19 DEBUG           net.crawler # Next parse result = ParseResult(scheme='http', netloc='localhost', path='/~map/testweb/index.html', params='', query='', fragment='')
22.11.16 01:53:19 DEBUG           net.crawler # Processing http://localhost/~map/testweb/index.html with hash value 44801ccea5dcbe4d3486f3c302c357a7
22.11.16 01:53:19 INFO            net.crawler # Url was already visited
22.11.16 01:53:19 INFO            net.crawler # No more urls to process.
22.11.16 01:53:19 INFO            net.crawler # web crawler 0.1 is done
22.11.16 01:57:29 INFO            net.crawler #             Application.name = web crawler
22.11.16 01:57:29 INFO            net.crawler #                      version = 0.1
22.11.16 01:57:29 INFO            net.crawler #                 inifile_name = undefined
22.11.16 01:57:29 INFO            net.crawler #                          log = <logging.Logger object at 0x7f3d71478f98>
22.11.16 01:57:29 INFO            net.crawler #        remote_logger_enabled = False
22.11.16 01:57:29 INFO            net.crawler #                 loghost_port = 9020
22.11.16 01:57:29 INFO            net.crawler #                 loghost_name = localhost
22.11.16 01:57:29 INFO            net.crawler #                      logfile = crawler.log
22.11.16 01:57:29 INFO            net.crawler #                 starting_url = http://localhost/~map/testweb/
22.11.16 01:57:29 INFO            net.crawler # web crawler 0.1 is starting
22.11.16 01:57:29 DEBUG           net.crawler # Next parse result = ParseResult(scheme='http', netloc='localhost', path='/~map/testweb/', params='', query='', fragment='')
22.11.16 01:57:29 DEBUG           net.crawler # Processing http://localhost/~map/testweb/ with hash value a82fca2019df9b43d0fa97f4cba277a5
22.11.16 01:57:29 INFO            net.crawler # Visiting http://localhost/~map/testweb/
22.11.16 01:57:29 DEBUG           crawler.parser # tld names were loaded: ['aaa', 'aarp', 'abarth', 'abb', 'abbott', 'abbvie', 'abc', 'able', 'abogado', 'abudhabi', 'ac', 'academy', 'accenture', 'accountant', 'accountants', 'aco', 'active', 'actor', 'ad', 'adac', 'ads', 'adult', 'ae', 'aeg', 'aero', 'aetna', 'af', 'afamilycompany', 'afl', 'ag', 'agakhan', 'agency', 'ai', 'aig', 'aigo', 'airbus', 'airforce', 'airtel', 'akdn', 'al', 'alfaromeo', 'alibaba', 'alipay', 'allfinanz', 'allstate', 'ally', 'alsace', 'alstom', 'am', 'americanexpress', 'americanfamily', 'amex', 'amfam', 'amica', 'amsterdam', 'analytics', 'android', 'anquan', 'anz', 'ao', 'apartments', 'app', 'apple', 'aq', 'aquarelle', 'ar', 'aramco', 'archi', 'army', 'arpa', 'art', 'arte', 'as', 'asda', 'asia', 'associates', 'at', 'athleta', 'attorney', 'au', 'auction', 'audi', 'audible', 'audio', 'auspost', 'author', 'auto', 'autos', 'avianca', 'aw', 'aws', 'ax', 'axa', 'az', 'azure', 'ba', 'baby', 'baidu', 'banamex', 'bananarepublic', 'band', 'bank', 'bar', 'barcelona', 'barclaycard', 'barclays', 'barefoot', 'bargains', 'bauhaus', 'bayern', 'bb', 'bbc', 'bbt', 'bbva', 'bcg', 'bcn', 'bd', 'be', 'beats', 'beauty', 'beer', 'bentley', 'berlin', 'best', 'bestbuy', 'bet', 'bf', 'bg', 'bh', 'bharti', 'bi', 'bible', 'bid', 'bike', 'bing', 'bingo', 'bio', 'biz', 'bj', 'black', 'blackfriday', 'blanco', 'blockbuster', 'blog', 'bloomberg', 'blue', 'bm', 'bms', 'bmw', 'bn', 'bnl', 'bnpparibas', 'bo', 'boats', 'boehringer', 'bofa', 'bom', 'bond', 'boo', 'book', 'booking', 'boots', 'bosch', 'bostik', 'bot', 'boutique', 'br', 'bradesco', 'bridgestone', 'broadway', 'broker', 'brother', 'brussels', 'bs', 'bt', 'budapest', 'bugatti', 'build', 'builders', 'business', 'buy', 'buzz', 'bv', 'bw', 'by', 'bz', 'bzh', 'ca', 'cab', 'cafe', 'cal', 'call', 'calvinklein', 'cam', 'camera', 'camp', 'cancerresearch', 'canon', 'capetown', 'capital', 'capitalone', 'car', 'caravan', 'cards', 'care', 'career', 'careers', 'cars', 'cartier', 'casa', 'cash', 'casino', 'cat', 'catering', 'cba', 'cbn', 'cbre', 'cbs', 'cc', 'cd', 'ceb', 'center', 'ceo', 'cern', 'cf', 'cfa', 'cfd', 'cg', 'ch', 'chanel', 'channel', 'chase', 'chat', 'cheap', 'chintai', 'chloe', 'christmas', 'chrome', 'chrysler', 'church', 'ci', 'cipriani', 'circle', 'cisco', 'citadel', 'citi', 'citic', 'city', 'cityeats', 'ck', 'cl', 'claims', 'cleaning', 'click', 'clinic', 'clinique', 'clothing', 'cloud', 'club', 'clubmed', 'cm', 'cn', 'co', 'coach', 'codes', 'coffee', 'college', 'cologne', 'com', 'comcast', 'commbank', 'community', 'company', 'compare', 'computer', 'comsec', 'condos', 'construction', 'consulting', 'contact', 'contractors', 'cooking', 'cookingchannel', 'cool', 'coop', 'corsica', 'country', 'coupon', 'coupons', 'courses', 'cr', 'credit', 'creditcard', 'creditunion', 'cricket', 'crown', 'crs', 'cruises', 'csc', 'cu', 'cuisinella', 'cv', 'cw', 'cx', 'cy', 'cymru', 'cyou', 'cz', 'dabur', 'dad', 'dance', 'date', 'dating', 'datsun', 'day', 'dclk', 'dds', 'de', 'deal', 'dealer', 'deals', 'degree', 'delivery', 'dell', 'deloitte', 'delta', 'democrat', 'dental', 'dentist', 'desi', 'design', 'dev', 'dhl', 'diamonds', 'diet', 'digital', 'direct', 'directory', 'discount', 'discover', 'dish', 'diy', 'dj', 'dk', 'dm', 'dnp', 'do', 'docs', 'doctor', 'dodge', 'dog', 'doha', 'domains', 'dot', 'download', 'drive', 'dtv', 'dubai', 'duck', 'dunlop', 'duns', 'dupont', 'durban', 'dvag', 'dvr', 'dz', 'earth', 'eat', 'ec', 'eco', 'edeka', 'edu', 'education', 'ee', 'eg', 'email', 'emerck', 'energy', 'engineer', 'engineering', 'enterprises', 'epost', 'epson', 'equipment', 'er', 'ericsson', 'erni', 'es', 'esq', 'estate', 'esurance', 'et', 'eu', 'eurovision', 'eus', 'events', 'everbank', 'exchange', 'expert', 'exposed', 'express', 'extraspace', 'fage', 'fail', 'fairwinds', 'faith', 'family', 'fan', 'fans', 'farm', 'farmers', 'fashion', 'fast', 'fedex', 'feedback', 'ferrari', 'ferrero', 'fi', 'fiat', 'fidelity', 'fido', 'film', 'final', 'finance', 'financial', 'fire', 'firestone', 'firmdale', 'fish', 'fishing', 'fit', 'fitness', 'fj', 'fk', 'flickr', 'flights', 'flir', 'florist', 'flowers', 'fly', 'fm', 'fo', 'foo', 'foodnetwork', 'football', 'ford', 'forex', 'forsale', 'forum', 'foundation', 'fox', 'fr', 'fresenius', 'frl', 'frogans', 'frontdoor', 'frontier', 'ftr', 'fujitsu', 'fujixerox', 'fund', 'furniture', 'futbol', 'fyi', 'ga', 'gal', 'gallery', 'gallo', 'gallup', 'game', 'games', 'gap', 'garden', 'gb', 'gbiz', 'gd', 'gdn', 'ge', 'gea', 'gent', 'genting', 'george', 'gf', 'gg', 'ggee', 'gh', 'gi', 'gift', 'gifts', 'gives', 'giving', 'gl', 'glade', 'glass', 'gle', 'global', 'globo', 'gm', 'gmail', 'gmbh', 'gmo', 'gmx', 'gn', 'godaddy', 'gold', 'goldpoint', 'golf', 'goo', 'goodhands', 'goodyear', 'goog', 'google', 'gop', 'got', 'gov', 'gp', 'gq', 'gr', 'grainger', 'graphics', 'gratis', 'green', 'gripe', 'group', 'gs', 'gt', 'gu', 'guardian', 'gucci', 'guge', 'guide', 'guitars', 'guru', 'gw', 'gy', 'hamburg', 'hangout', 'haus', 'hbo', 'hdfc', 'hdfcbank', 'health', 'healthcare', 'help', 'helsinki', 'here', 'hermes', 'hgtv', 'hiphop', 'hisamitsu', 'hitachi', 'hiv', 'hk', 'hkt', 'hm', 'hn', 'hockey', 'holdings', 'holiday', 'homedepot', 'homegoods', 'homes', 'homesense', 'honda', 'honeywell', 'horse', 'host', 'hosting', 'hot', 'hoteles', 'hotmail', 'house', 'how', 'hr', 'hsbc', 'ht', 'htc', 'hu', 'hughes', 'hyatt', 'hyundai', 'ibm', 'icbc', 'ice', 'icu', 'id', 'ie', 'ieee', 'ifm', 'iinet', 'ikano', 'il', 'im', 'imamat', 'imdb', 'immo', 'immobilien', 'in', 'industries', 'infiniti', 'info', 'ing', 'ink', 'institute', 'insurance', 'insure', 'int', 'intel', 'international', 'intuit', 'investments', 'io', 'ipiranga', 'iq', 'ir', 'irish', 'is', 'iselect', 'ismaili', 'ist', 'istanbul', 'it', 'itau', 'itv', 'iwc', 'jaguar', 'java', 'jcb', 'jcp', 'je', 'jeep', 'jetzt', 'jewelry', 'jlc', 'jll', 'jm', 'jmp', 'jnj', 'jo', 'jobs', 'joburg', 'jot', 'joy', 'jp', 'jpmorgan', 'jprs', 'juegos', 'juniper', 'kaufen', 'kddi', 'ke', 'kerryhotels', 'kerrylogistics', 'kerryproperties', 'kfh', 'kg', 'kh', 'ki', 'kia', 'kim', 'kinder', 'kindle', 'kitchen', 'kiwi', 'km', 'kn', 'koeln', 'komatsu', 'kosher', 'kp', 'kpmg', 'kpn', 'kr', 'krd', 'kred', 'kuokgroup', 'kw', 'ky', 'kyoto', 'kz', 'la', 'lacaixa', 'ladbrokes', 'lamborghini', 'lamer', 'lancaster', 'lancia', 'lancome', 'land', 'landrover', 'lanxess', 'lasalle', 'lat', 'latino', 'latrobe', 'law', 'lawyer', 'lb', 'lc', 'lds', 'lease', 'leclerc', 'lefrak', 'legal', 'lego', 'lexus', 'lgbt', 'li', 'liaison', 'lidl', 'life', 'lifeinsurance', 'lifestyle', 'lighting', 'like', 'lilly', 'limited', 'limo', 'lincoln', 'linde', 'link', 'lipsy', 'live', 'living', 'lixil', 'lk', 'loan', 'loans', 'locker', 'locus', 'loft', 'lol', 'london', 'lotte', 'lotto', 'love', 'lpl', 'lplfinancial', 'lr', 'ls', 'lt', 'ltd', 'ltda', 'lu', 'lundbeck', 'lupin', 'luxe', 'luxury', 'lv', 'ly', 'ma', 'macys', 'madrid', 'maif', 'maison', 'makeup', 'man', 'management', 'mango', 'market', 'marketing', 'markets', 'marriott', 'marshalls', 'maserati', 'mattel', 'mba', 'mc', 'mcd', 'mcdonalds', 'mckinsey', 'md', 'me', 'med', 'media', 'meet', 'melbourne', 'meme', 'memorial', 'men', 'menu', 'meo', 'metlife', 'mg', 'mh', 'miami', 'microsoft', 'mil', 'mini', 'mint', 'mit', 'mitsubishi', 'mk', 'ml', 'mlb', 'mls', 'mm', 'mma', 'mn', 'mo', 'mobi', 'mobily', 'moda', 'moe', 'moi', 'mom', 'monash', 'money', 'monster', 'montblanc', 'mopar', 'mormon', 'mortgage', 'moscow', 'motorcycles', 'mov', 'movie', 'movistar', 'mp', 'mq', 'mr', 'ms', 'msd', 'mt', 'mtn', 'mtpc', 'mtr', 'mu', 'museum', 'mutual', 'mutuelle', 'mv', 'mw', 'mx', 'my', 'mz', 'na', 'nab', 'nadex', 'nagoya', 'name', 'nationwide', 'natura', 'navy', 'nba', 'nc', 'ne', 'nec', 'net', 'netbank', 'netflix', 'network', 'neustar', 'new', 'news', 'next', 'nextdirect', 'nexus', 'nf', 'nfl', 'ng', 'ngo', 'nhk', 'ni', 'nico', 'nike', 'nikon', 'ninja', 'nissan', 'nissay', 'nl', 'no', 'nokia', 'northwesternmutual', 'norton', 'now', 'nowruz', 'nowtv', 'np', 'nr', 'nra', 'nrw', 'ntt', 'nu', 'nyc', 'nz', 'obi', 'observer', 'off', 'office', 'okinawa', 'olayan', 'olayangroup', 'oldnavy', 'ollo', 'om', 'omega', 'one', 'ong', 'onl', 'online', 'onyourside', 'ooo', 'open', 'oracle', 'orange', 'org', 'organic', 'orientexpress', 'origins', 'osaka', 'otsuka', 'ott', 'ovh', 'pa', 'page', 'pamperedchef', 'panasonic', 'panerai', 'paris', 'pars', 'partners', 'parts', 'party', 'passagens', 'pay', 'pccw', 'pe', 'pet', 'pf', 'pfizer', 'pg', 'ph', 'pharmacy', 'philips', 'photo', 'photography', 'photos', 'physio', 'piaget', 'pics', 'pictet', 'pictures', 'pid', 'pin', 'ping', 'pink', 'pioneer', 'pizza', 'pk', 'pl', 'place', 'play', 'playstation', 'plumbing', 'plus', 'pm', 'pn', 'pnc', 'pohl', 'poker', 'politie', 'porn', 'post', 'pr', 'pramerica', 'praxi', 'press', 'prime', 'pro', 'prod', 'productions', 'prof', 'progressive', 'promo', 'properties', 'property', 'protection', 'pru', 'prudential', 'ps', 'pt', 'pub', 'pw', 'pwc', 'py', 'qa', 'qpon', 'quebec', 'quest', 'qvc', 'racing', 'raid', 're', 'read', 'realestate', 'realtor', 'realty', 'recipes', 'red', 'redstone', 'redumbrella', 'rehab', 'reise', 'reisen', 'reit', 'ren', 'rent', 'rentals', 'repair', 'report', 'republican', 'rest', 'restaurant', 'review', 'reviews', 'rexroth', 'rich', 'richardli', 'ricoh', 'rightathome', 'rio', 'rip', 'ro', 'rocher', 'rocks', 'rodeo', 'rogers', 'room', 'rs', 'rsvp', 'ru', 'ruhr', 'run', 'rw', 'rwe', 'ryukyu', 'sa', 'saarland', 'safe', 'safety', 'sakura', 'sale', 'salon', 'samsclub', 'samsung', 'sandvik', 'sandvikcoromant', 'sanofi', 'sap', 'sapo', 'sarl', 'sas', 'save', 'saxo', 'sb', 'sbi', 'sbs', 'sc', 'sca', 'scb', 'schaeffler', 'schmidt', 'scholarships', 'school', 'schule', 'schwarz', 'science', 'scjohnson', 'scor', 'scot', 'sd', 'se', 'seat', 'secure', 'security', 'seek', 'select', 'sener', 'services', 'ses', 'seven', 'sew', 'sex', 'sexy', 'sfr', 'sg', 'sh', 'shangrila', 'sharp', 'shaw', 'shell', 'shia', 'shiksha', 'shoes', 'shop', 'shopping', 'shouji', 'show', 'showtime', 'shriram', 'si', 'silk', 'sina', 'singles', 'site', 'sj', 'sk', 'ski', 'skin', 'sky', 'skype', 'sl', 'sling', 'sm', 'smart', 'smile', 'sn', 'sncf', 'so', 'soccer', 'social', 'softbank', 'software', 'sohu', 'solar', 'solutions', 'song', 'sony', 'soy', 'space', 'spiegel', 'spot', 'spreadbetting', 'sr', 'srl', 'srt', 'st', 'stada', 'staples', 'star', 'starhub', 'statebank', 'statefarm', 'statoil', 'stc', 'stcgroup', 'stockholm', 'storage', 'store', 'stream', 'studio', 'study', 'style', 'su', 'sucks', 'supplies', 'supply', 'support', 'surf', 'surgery', 'suzuki', 'sv', 'swatch', 'swiftcover', 'swiss', 'sx', 'sy', 'sydney', 'symantec', 'systems', 'sz', 'tab', 'taipei', 'talk', 'taobao', 'target', 'tatamotors', 'tatar', 'tattoo', 'tax', 'taxi', 'tc', 'tci', 'td', 'tdk', 'team', 'tech', 'technology', 'tel', 'telecity', 'telefonica', 'temasek', 'tennis', 'teva', 'tf', 'tg', 'th', 'thd', 'theater', 'theatre', 'tiaa', 'tickets', 'tienda', 'tiffany', 'tips', 'tires', 'tirol', 'tj', 'tjmaxx', 'tjx', 'tk', 'tkmaxx', 'tl', 'tm', 'tmall', 'tn', 'to', 'today', 'tokyo', 'tools', 'top', 'toray', 'toshiba', 'total', 'tours', 'town', 'toyota', 'toys', 'tr', 'trade', 'trading', 'training', 'travel', 'travelchannel', 'travelers', 'travelersinsurance', 'trust', 'trv', 'tt', 'tube', 'tui', 'tunes', 'tushu', 'tv', 'tvs', 'tw', 'tz', 'ua', 'ubank', 'ubs', 'uconnect', 'ug', 'uk', 'unicom', 'university', 'uno', 'uol', 'ups', 'us', 'uy', 'uz', 'va', 'vacations', 'vana', 'vanguard', 'vc', 've', 'vegas', 'ventures', 'verisign', 'versicherung', 'vet', 'vg', 'vi', 'viajes', 'video', 'vig', 'viking', 'villas', 'vin', 'vip', 'virgin', 'visa', 'vision', 'vista', 'vistaprint', 'viva', 'vivo', 'vlaanderen', 'vn', 'vodka', 'volkswagen', 'vote', 'voting', 'voto', 'voyage', 'vu', 'vuelos', 'wales', 'walmart', 'walter', 'wang', 'wanggou', 'warman', 'watch', 'watches', 'weather', 'weatherchannel', 'webcam', 'weber', 'website', 'wed', 'wedding', 'weibo', 'weir', 'wf', 'whoswho', 'wien', 'wiki', 'williamhill', 'win', 'windows', 'wine', 'winners', 'wme', 'wolterskluwer', 'woodside', 'work', 'works', 'world', 'wow', 'ws', 'wtc', 'wtf', 'xbox', 'xerox', 'xfinity', 'xihuan', 'xin', 'xn--11b4c3d', 'xn--1ck2e1b', 'xn--1qqw23a', 'xn--30rr7y', 'xn--3bst00m', 'xn--3ds443g', 'xn--3e0b707e', 'xn--3oq18vl8pn36a', 'xn--3pxu8k', 'xn--42c2d9a', 'xn--45brj9c', 'xn--45q11c', 'xn--4gbrim', 'xn--55qw42g', 'xn--55qx5d', 'xn--5su34j936bgsg', 'xn--5tzm5g', 'xn--6frz82g', 'xn--6qq986b3xl', 'xn--80adxhks', 'xn--80ao21a', 'xn--80asehdb', 'xn--80aswg', 'xn--8y0a063a', 'xn--90a3ac', 'xn--90ae', 'xn--90ais', 'xn--9dbq2a', 'xn--9et52u', 'xn--9krt00a', 'xn--b4w605ferd', 'xn--bck1b9a5dre4c', 'xn--c1avg', 'xn--c2br7g', 'xn--cck2b3b', 'xn--cg4bki', 'xn--clchc0ea0b2g2a9gcd', 'xn--czr694b', 'xn--czrs0t', 'xn--czru2d', 'xn--d1acj3b', 'xn--d1alf', 'xn--e1a4c', 'xn--eckvdtc9d', 'xn--efvy88h', 'xn--estv75g', 'xn--fct429k', 'xn--fhbei', 'xn--fiq228c5hs', 'xn--fiq64b', 'xn--fiqs8s', 'xn--fiqz9s', 'xn--fjq720a', 'xn--flw351e', 'xn--fpcrj9c3d', 'xn--fzc2c9e2c', 'xn--fzys8d69uvgm', 'xn--g2xx48c', 'xn--gckr3f0f', 'xn--gecrj9c', 'xn--gk3at1e', 'xn--h2brj9c', 'xn--hxt814e', 'xn--i1b6b1a6a2e', 'xn--imr513n', 'xn--io0a7i', 'xn--j1aef', 'xn--j1amh', 'xn--j6w193g', 'xn--jlq61u9w7b', 'xn--jvr189m', 'xn--kcrx77d1x4a', 'xn--kprw13d', 'xn--kpry57d', 'xn--kpu716f', 'xn--kput3i', 'xn--l1acc', 'xn--lgbbat1ad8j', 'xn--mgb9awbf', 'xn--mgba3a3ejt', 'xn--mgba3a4f16a', 'xn--mgba7c0bbn0a', 'xn--mgbaam7a8h', 'xn--mgbab2bd', 'xn--mgbayh7gpa', 'xn--mgbb9fbpob', 'xn--mgbbh1a71e', 'xn--mgbc0a9azcg', 'xn--mgbca7dzdo', 'xn--mgberp4a5d4ar', 'xn--mgbpl2fh', 'xn--mgbt3dhd', 'xn--mgbtx2b', 'xn--mgbx4cd0ab', 'xn--mix891f', 'xn--mk1bu44c', 'xn--mxtq1m', 'xn--ngbc5azd', 'xn--ngbe9e0a', 'xn--node', 'xn--nqv7f', 'xn--nqv7fs00ema', 'xn--nyqy26a', 'xn--o3cw4h', 'xn--ogbpf8fl', 'xn--p1acf', 'xn--p1ai', 'xn--pbt977c', 'xn--pgbs0dh', 'xn--pssy2u', 'xn--q9jyb4c', 'xn--qcka1pmc', 'xn--qxam', 'xn--rhqv96g', 'xn--rovu88b', 'xn--s9brj9c', 'xn--ses554g', 'xn--t60b56a', 'xn--tckwe', 'xn--unup4y', 'xn--vermgensberater-ctb', 'xn--vermgensberatung-pwb', 'xn--vhquv', 'xn--vuq861b', 'xn--w4r85el8fhu5dnra', 'xn--w4rs40l', 'xn--wgbh1c', 'xn--wgbl6a', 'xn--xhq521b', 'xn--xkc2al3hye2a', 'xn--xkc2dl3a5ee0h', 'xn--y9a3aq', 'xn--yfro4i67o', 'xn--ygbi2ammx', 'xn--zfr164b', 'xperia', 'xxx', 'xyz', 'yachts', 'yahoo', 'yamaxun', 'yandex', 'ye', 'yodobashi', 'yoga', 'yokohama', 'you', 'youtube', 'yt', 'yun', 'za', 'zappos', 'zara', 'zero', 'zip', 'zippo', 'zm', 'zone', 'zuerich', 'zw']
22.11.16 01:57:29 DEBUG           crawler.parser # Stopwords were loaded: ['a', 'able', 'about', 'across', 'after', 'all', 'almost', 'also', 'am', 'among', 'an', 'and', 'any', 'are', 'as', 'at', 'be', 'because', 'been', 'but', 'by', 'can', 'cannot', 'could', 'dear', 'did', 'do', 'does', 'either', 'else', 'ever', 'every', 'for', 'from', 'get', 'got', 'had', 'has', 'have', 'he', 'her', 'hers', 'him', 'his', 'how', 'however', 'i', 'if', 'in', 'into', 'is', 'it', 'its', 'just', 'least', 'let', 'like', 'likely', 'may', 'me', 'might', 'most', 'must', 'my', 'neither', 'no', 'nor', 'not', 'of', 'off', 'often', 'on', 'only', 'or', 'other', 'our', 'own', 'rather', 'said', 'say', 'says', 'she', 'should', 'since', 'so', 'some', 'than', 'that', 'the', 'their', 'them', 'then', 'there', 'these', 'they', 'this', 'tis', 'to', 'too', 'twas', 'us', 'wants', 'was', 'we', 'were', 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'would', 'yet', 'you', 'your']
22.11.16 01:57:29 DEBUG           crawler.parser # Guessing charset for url http://localhost/~map/testweb/: iso-8859-1
22.11.16 01:57:29 INFO            crawler.parser # histogram = {'blue': 1, 'red': 1, 'laus': 1, 'haus': 1, 'link': 1, 'klaus': 1, 'hund': 4, 'maus': 1, 'green': 1, 'katze': 1}
22.11.16 01:57:29 INFO            crawler.parser # Keywords = {'red': 1, 'laus': 1, 'link': 1, 'haus': 1, 'hund': 4}
22.11.16 01:57:29 DEBUG           net.crawler # Next parse result = ParseResult(scheme='http', netloc='localhost', path='/~map/testweb/index2.html', params='', query='', fragment='')
22.11.16 01:57:29 DEBUG           net.crawler # Processing http://localhost/~map/testweb/index2.html with hash value 2a7a5d436306036d85f26b30160cff48
22.11.16 01:57:29 INFO            net.crawler # Visiting http://localhost/~map/testweb/index2.html
22.11.16 01:57:29 DEBUG           crawler.parser # Guessing charset for url http://localhost/~map/testweb/index2.html: iso-8859-1
22.11.16 01:57:29 INFO            crawler.parser # histogram = {'large': 1, 'auto': 7, 'small': 1, 'middle': 1, 'link': 1}
22.11.16 01:57:29 INFO            crawler.parser # Keywords = {'auto': 7, 'small': 1, 'middle': 1, 'link': 1}
22.11.16 01:57:29 DEBUG           net.crawler # Next parse result = ParseResult(scheme='http', netloc='localhost', path='/~map/testweb/index3.html', params='', query='', fragment='')
22.11.16 01:57:29 DEBUG           net.crawler # Processing http://localhost/~map/testweb/index3.html with hash value 4034293276428b374ccd042e062424e3
22.11.16 01:57:29 INFO            net.crawler # Visiting http://localhost/~map/testweb/index3.html
22.11.16 01:57:29 DEBUG           crawler.parser # Guessing charset for url http://localhost/~map/testweb/index3.html: iso-8859-1
22.11.16 01:57:29 INFO            crawler.parser # histogram = {'toyota': 1, 'verzeichnisdienst': 3, 'vw': 1, 'bmw': 1, 'link': 3}
22.11.16 01:57:29 INFO            crawler.parser # Keywords = {'verzeichnisdienst': 3, 'bmw': 1, 'link': 3}
22.11.16 01:57:29 DEBUG           net.crawler # Next parse result = ParseResult(scheme='http', netloc='localhost', path='/~map/testweb/index6.html', params='', query='', fragment='')
22.11.16 01:57:29 DEBUG           net.crawler # Processing http://localhost/~map/testweb/index6.html with hash value 1614847c29f2ae14d8c886e97ee64667
22.11.16 01:57:29 INFO            net.crawler # Visiting http://localhost/~map/testweb/index6.html
22.11.16 01:57:29 DEBUG           crawler.parser # Guessing charset for url http://localhost/~map/testweb/index6.html: iso-8859-1
22.11.16 01:57:29 INFO            crawler.parser # histogram = {'london': 1, 'birmingham': 1, 'piratenschiff': 26, 'glasgow': 1, 'link': 1}
22.11.16 01:57:29 INFO            crawler.parser # Keywords = {'glasgow': 1, 'birmingham': 1, 'piratenschiff': 26, 'link': 1}
22.11.16 01:57:29 DEBUG           net.crawler # Next parse result = ParseResult(scheme='http', netloc='localhost', path='/~map/testweb/index.html', params='', query='', fragment='')
22.11.16 01:57:29 DEBUG           net.crawler # Processing http://localhost/~map/testweb/index.html with hash value 44801ccea5dcbe4d3486f3c302c357a7
22.11.16 01:57:29 INFO            net.crawler # Visiting http://localhost/~map/testweb/index.html
22.11.16 01:57:29 DEBUG           crawler.parser # Guessing charset for url http://localhost/~map/testweb/index.html: iso-8859-1
22.11.16 01:57:29 INFO            crawler.parser # histogram = {'blue': 1, 'red': 1, 'laus': 1, 'haus': 1, 'link': 1, 'klaus': 1, 'hund': 4, 'maus': 1, 'green': 1, 'katze': 1}
22.11.16 01:57:29 INFO            crawler.parser # Keywords = {'red': 1, 'laus': 1, 'link': 1, 'haus': 1, 'hund': 4}
22.11.16 01:57:29 DEBUG           net.crawler # Next parse result = ParseResult(scheme='http', netloc='localhost', path='/~map/testweb/index2.html', params='', query='', fragment='')
22.11.16 01:57:29 DEBUG           net.crawler # Processing http://localhost/~map/testweb/index2.html with hash value 2a7a5d436306036d85f26b30160cff48
22.11.16 01:57:29 INFO            net.crawler # Url was already visited
22.11.16 01:57:29 DEBUG           net.crawler # Next parse result = ParseResult(scheme='http', netloc='localhost', path='/~map/testweb/index5.html', params='', query='', fragment='')
22.11.16 01:57:29 DEBUG           net.crawler # Processing http://localhost/~map/testweb/index5.html with hash value 7f41433a058018edd43b03fe18c9c325
22.11.16 01:57:29 INFO            net.crawler # Visiting http://localhost/~map/testweb/index5.html
22.11.16 01:57:29 DEBUG           crawler.parser # Guessing charset for url http://localhost/~map/testweb/index5.html: iso-8859-1
22.11.16 01:57:29 INFO            crawler.parser # histogram = {'paris': 1, 'montpellier': 1, 'klabautermann': 19, 'nice': 1, 'link': 1}
22.11.16 01:57:29 INFO            crawler.parser # Keywords = {'montpellier': 1, 'klabautermann': 19, 'nice': 1, 'link': 1}
22.11.16 01:57:29 DEBUG           net.crawler # Next parse result = ParseResult(scheme='http', netloc='localhost', path='/~map/testweb/index.html', params='', query='', fragment='')
22.11.16 01:57:29 DEBUG           net.crawler # Processing http://localhost/~map/testweb/index.html with hash value 44801ccea5dcbe4d3486f3c302c357a7
22.11.16 01:57:29 INFO            net.crawler # Url was already visited
22.11.16 01:57:29 DEBUG           net.crawler # Next parse result = ParseResult(scheme='http', netloc='localhost', path='/~map/testweb/index4.html', params='', query='', fragment='')
22.11.16 01:57:29 DEBUG           net.crawler # Processing http://localhost/~map/testweb/index4.html with hash value d95f56b91c09e0cf0daf83f8dfa0a041
22.11.16 01:57:29 INFO            net.crawler # Visiting http://localhost/~map/testweb/index4.html
22.11.16 01:57:29 DEBUG           crawler.parser # Guessing charset for url http://localhost/~map/testweb/index4.html: iso-8859-1
22.11.16 01:57:29 INFO            crawler.parser # histogram = {'hamburg': 1, 'aachen': 1, 'link': 1, 'volkswagen': 18, 'berlin': 1}
22.11.16 01:57:29 INFO            crawler.parser # Keywords = {'berlin': 1, 'aachen': 1, 'volkswagen': 18, 'link': 1}
22.11.16 01:57:29 DEBUG           net.crawler # Next parse result = ParseResult(scheme='http', netloc='localhost', path='/~map/testweb/index.html', params='', query='', fragment='')
22.11.16 01:57:29 DEBUG           net.crawler # Processing http://localhost/~map/testweb/index.html with hash value 44801ccea5dcbe4d3486f3c302c357a7
22.11.16 01:57:29 INFO            net.crawler # Url was already visited
22.11.16 01:57:29 INFO            net.crawler # No more urls to process.
22.11.16 01:57:29 INFO            net.crawler # web crawler 0.1 is done
